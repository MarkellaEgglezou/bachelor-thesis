{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Chatbot Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import mannwhitneyu, shapiro\n",
    "from statsmodels.multivariate.manova import MANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = pd.read_csv('neg_ch.csv')\n",
    "pos_data = pd.read_csv('pos_ch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discard the first column, which has the questionnaire answer timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = neg_data.iloc[:, 1:]\n",
    "pos_data = pos_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rename all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [\n",
    "    \"Gender\", \"Age\", \"Education\", \"Frequency\",\n",
    "    \"CS1\", \"CS2\", \"CS3\", \"CS4\", \n",
    "    \"T1\", \"T2\", \"T3\",\n",
    "    \"PE1\", \"PE2\", \"PE3\", \"PE4\", \"PE5\",\n",
    "    \"PWOM1\", \"PWOM2\", \"PWOM3\", \"PWOM4\", \"PWOM5\",\n",
    "    \"CI1\", \"CI2\",\n",
    "    \"TBF1\", \"TBF2\", \"TBF3\",\n",
    "    \"TBR1\", \"TBR2\", \"TBR3\",\n",
    "    \"TBI1\", \"TBI2\",\n",
    "    \"TBC1\", \"TBC2\", \"TBC3\",\n",
    "    \"TBB1\", \"TBB2\", \"TBB3\"\n",
    "]\n",
    "\n",
    "neg_data.columns = new_column_names\n",
    "pos_data.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Code the categorical columns into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data['Gender Coded'] = neg_data['Gender'].map({'Male': 0, 'Female': 1, 'Other': 2})\n",
    "neg_data['Age Coded'] = neg_data['Age'].map({'18-24': 0, '25-34': 1, '35-49': 2, '50+': 3})\n",
    "neg_data['Education Coded'] = neg_data['Education'].map({'Middle School': 0, 'High School': 1, 'University': 2, 'Post-graduate Studies': 3})\n",
    "neg_data['Frequency Coded'] = neg_data['Frequency'].map({'Several times a day': 0, 'Nearly everyday': 1, 'At least once a week': 2,\n",
    "                                                 'Less than once a month': 3, 'Never': 4})\n",
    "\n",
    "pos_data['Gender Coded'] = pos_data['Gender'].map({'Male': 0, 'Female': 1, 'Other': 2})\n",
    "pos_data['Age Coded'] = pos_data['Age'].map({'18-24': 0, '25-34': 1, '35-49': 2, '50+': 3})\n",
    "pos_data['Education Coded'] = pos_data['Education'].map({'Middle School': 0, 'High School': 1, 'University': 2, 'Post-graduate Studies': 3})\n",
    "pos_data['Frequency Coded'] = pos_data['Frequency'].map({'Several times a day': 0, 'Nearly everyday': 1, 'At least once a week': 2,\n",
    "                                                 'Less than once a month': 3, 'Never': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create dummy variables for each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = pd.get_dummies(neg_data, columns=['Gender Coded', 'Age Coded', 'Education Coded', 'Frequency Coded'], drop_first=False)\n",
    "pos_data = pd.get_dummies(pos_data, columns=['Gender Coded', 'Age Coded', 'Education Coded', 'Frequency Coded'], drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set construct names and codings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct = {\n",
    "    \"Customer Satisfaction\": [\"CS1\", \"CS2\", \"CS3\", \"CS4\"],\n",
    "    \"Trust\": [\"T1\", \"T2\", \"T3\"],\n",
    "    \"Positive Emotions\": [\"PE1\", \"PE2\", \"PE3\", \"PE4\", \"PE5\"],\n",
    "    \"Positive Word of Mouth\": [\"PWOM1\", \"PWOM2\", \"PWOM3\", \"PWOM4\", \"PWOM5\"],\n",
    "    \"Continuance Intention\": [\"CI1\", \"CI2\"],\n",
    "    \"TTB - Functionality\": [\"TBF1\", \"TBF2\", \"TBF3\"],\n",
    "    \"TTB - Reliability\": [\"TBR1\", \"TBR2\", \"TBR3\"],\n",
    "    \"TTB - Integrity\": [\"TBI1\", \"TBI2\"],\n",
    "    \"TTB - Competence\": [\"TBC1\", \"TBC2\", \"TBC3\"],\n",
    "    \"TTB - Benevolence\": [\"TBB1\", \"TBB2\", \"TBB3\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney U Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Mann-Whitney U Test to compare each chatbot and positive emotions. (H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test (Positive Group): p = 0.0003\n",
      "Shapiro-Wilk test (Negative Group): p = 0.2586\n"
     ]
    }
   ],
   "source": [
    "# Aggregate positive emotion scores\n",
    "pos_data['PE'] = pos_data[['PE1', 'PE2', 'PE3', 'PE4', 'PE5']].mean(axis=1)\n",
    "neg_data['PE'] = neg_data[['PE1', 'PE2', 'PE3', 'PE4', 'PE5']].mean(axis=1)\n",
    "\n",
    "# Check pos_data normality\n",
    "shapiro_pos = shapiro(pos_data['PE'])\n",
    "print(f\"Shapiro-Wilk test (Positive Group): p = {shapiro_pos.pvalue:.4f}\")\n",
    "\n",
    "# Check neg_data normality\n",
    "shapiro_neg = shapiro(neg_data['PE'])\n",
    "print(f\"Shapiro-Wilk test (Negative Group): p = {shapiro_neg.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test: U = 783.0, p-value = 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Use Mann-Whitney U Test since normality failed\n",
    "u_stat, p_val = mannwhitneyu(pos_data['PE'], neg_data['PE'], alternative='two-sided')\n",
    "print(f\"Mann-Whitney U test: U = {u_stat}, p-value = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Mann-Whitney U Test to compare each chatbot and trust. (H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test (Positive Group): p = 0.0012\n",
      "Shapiro-Wilk test (Negative Group): p = 0.2426\n"
     ]
    }
   ],
   "source": [
    "# Aggregate trust scores\n",
    "pos_data['T'] = pos_data[['T1', 'T2', 'T3']].mean(axis=1)\n",
    "neg_data['T'] = neg_data[['T1', 'T2', 'T3']].mean(axis=1)\n",
    "\n",
    "# Check pos_data normality\n",
    "shapiro_pos = shapiro(pos_data['T'])\n",
    "print(f\"Shapiro-Wilk test (Positive Group): p = {shapiro_pos.pvalue:.4f}\")\n",
    "\n",
    "# Check neg_data normality\n",
    "shapiro_neg = shapiro(neg_data['T'])\n",
    "print(f\"Shapiro-Wilk test (Negative Group): p = {shapiro_neg.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test: U = 679.5, p-value = 0.0239\n"
     ]
    }
   ],
   "source": [
    "# Use Mann-Whitney U Test since normality failed\n",
    "u_stat, p_val = mannwhitneyu(pos_data['T'], neg_data['T'], alternative='two-sided')\n",
    "print(f\"Mann-Whitney U test: U = {u_stat}, p-value = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Mann-Whitney U Test to compare each chatbot and customer satisfaction. (H6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test (Positive Group): p = 0.0019\n",
      "Shapiro-Wilk test (Negative Group): p = 0.5641\n"
     ]
    }
   ],
   "source": [
    "# Aggregate customer satisfaction scores\n",
    "pos_data['CS'] = pos_data[['CS1', 'CS2', 'CS3', 'CS4']].mean(axis=1)\n",
    "neg_data['CS'] = neg_data[['CS1', 'CS2', 'CS3', 'CS4']].mean(axis=1)\n",
    "\n",
    "# Check pos_data normality\n",
    "shapiro_pos = shapiro(pos_data['CS'])\n",
    "print(f\"Shapiro-Wilk test (Positive Group): p = {shapiro_pos.pvalue:.4f}\")\n",
    "\n",
    "# Check neg_data normality\n",
    "shapiro_neg = shapiro(neg_data['CS'])\n",
    "print(f\"Shapiro-Wilk test (Negative Group): p = {shapiro_neg.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test: U = 788.0, p-value = 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Use Mann-Whitney U Test since normality failed\n",
    "u_stat, p_val = mannwhitneyu(pos_data['CS'], neg_data['CS'], alternative='two-sided')\n",
    "print(f\"Mann-Whitney U test: U = {u_stat}, p-value = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Mann-Whitney U Test to compare each chatbot and positive word of mouth intention. (H7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test (Positive Group): p = 0.0025\n",
      "Shapiro-Wilk test (Negative Group): p = 0.2603\n"
     ]
    }
   ],
   "source": [
    "# Aggregate positive positive word of mouth intention scores\n",
    "pos_data['PWoM'] = pos_data[['PWOM1', 'PWOM2', 'PWOM3', 'PWOM4', 'PWOM5']].mean(axis=1)\n",
    "neg_data['PWoM'] = neg_data[['PWOM1', 'PWOM2', 'PWOM3', 'PWOM4', 'PWOM5']].mean(axis=1)\n",
    "\n",
    "# Check pos_data normality\n",
    "shapiro_pos = shapiro(pos_data['PWoM'])\n",
    "print(f\"Shapiro-Wilk test (Positive Group): p = {shapiro_pos.pvalue:.4f}\")\n",
    "\n",
    "# Check neg_data normality\n",
    "shapiro_neg = shapiro(neg_data['PWoM'])\n",
    "print(f\"Shapiro-Wilk test (Negative Group): p = {shapiro_neg.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test: U = 735.5, p-value = 0.0027\n"
     ]
    }
   ],
   "source": [
    "# Use Mann-Whitney U Test since normality failed\n",
    "u_stat, p_val = mannwhitneyu(pos_data['PWoM'], neg_data['PWoM'], alternative='two-sided')\n",
    "print(f\"Mann-Whitney U test: U = {u_stat}, p-value = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANOVA (Multivariate Analysis of Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use MANOVA to compare each chatbot and technology trusting beliefs. (H3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Multivariate linear model\n",
      "==============================================================\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "       Intercept         Value  Num DF  Den DF F Value  Pr > F\n",
      "--------------------------------------------------------------\n",
      "          Wilks' lambda  0.0787 5.0000 58.0000 135.8301 0.0000\n",
      "         Pillai's trace  0.9213 5.0000 58.0000 135.8301 0.0000\n",
      " Hotelling-Lawley trace 11.7095 5.0000 58.0000 135.8301 0.0000\n",
      "    Roy's greatest root 11.7095 5.0000 58.0000 135.8301 0.0000\n",
      "--------------------------------------------------------------\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "         Sentiment        Value  Num DF  Den DF F Value Pr > F\n",
      "--------------------------------------------------------------\n",
      "            Wilks' lambda 0.7897 5.0000 58.0000  3.0896 0.0154\n",
      "           Pillai's trace 0.2103 5.0000 58.0000  3.0896 0.0154\n",
      "   Hotelling-Lawley trace 0.2663 5.0000 58.0000  3.0896 0.0154\n",
      "      Roy's greatest root 0.2663 5.0000 58.0000  3.0896 0.0154\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate TTB - Functionality mean\n",
    "pos_data['Functionality'] = pos_data[['TBF1', 'TBF2', 'TBF3']].mean(axis=1)\n",
    "neg_data['Functionality'] = neg_data[['TBF1', 'TBF2', 'TBF3']].mean(axis=1)\n",
    "\n",
    "# Calculate TTB - Reliability mean\n",
    "pos_data['Reliability'] = pos_data[['TBR1', 'TBR2', 'TBR3']].mean(axis=1)\n",
    "neg_data['Reliability'] = neg_data[['TBR1', 'TBR2', 'TBR3']].mean(axis=1)\n",
    "\n",
    "# Calculate TTB - Integrity mean\n",
    "pos_data['Integrity'] = pos_data[['TBI1', 'TBI2']].mean(axis=1)\n",
    "neg_data['Integrity'] = neg_data[['TBI1', 'TBI2']].mean(axis=1)\n",
    "\n",
    "# Calculate TTB - Competence mean\n",
    "pos_data['Competence'] = pos_data[['TBC1', 'TBC2', 'TBC3']].mean(axis=1)\n",
    "neg_data['Competence'] = neg_data[['TBC1', 'TBC2', 'TBC3']].mean(axis=1)\n",
    "\n",
    "# Calculate TTB - Benevolence mean\n",
    "pos_data['Benevolence'] = pos_data[['TBB1', 'TBB2', 'TBB3']].mean(axis=1)\n",
    "neg_data['Benevolence'] = neg_data[['TBB1', 'TBB2', 'TBB3']].mean(axis=1)\n",
    "\n",
    "# Add sentiment labels\n",
    "pos_data['Sentiment'] = 'positive'\n",
    "neg_data['Sentiment'] = 'negative'\n",
    "\n",
    "# Combine the two\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# MANOVA for TTB sub-constructs\n",
    "maov = MANOVA.from_formula(\n",
    "    'Functionality + Reliability + Integrity + Competence + Benevolence ~ Sentiment',\n",
    "    data=combined_data\n",
    ")\n",
    "print(maov.mv_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
